{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2QdXTBeOXET"
   },
   "source": [
    "<html>\n",
    "<body>\n",
    "<h1>Explainable_Medical_Image_Classifier_based_on_Human_Diagnosis_Behaviour_PT</h1>\n",
    "<h4>Author: Anshu Garg </h4>\n",
    "<h4>Matriculation Number: 414686</h4>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WEc0iGXwB6MZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\acvdl\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'E:\\Anaconda\\envs\\acvdl\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tr4vnldGB6Mq"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.40, 0.45, 0.45], std=[0.21, 0.23, 0.22]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eq_7o8USB6M5"
   },
   "outputs": [],
   "source": [
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "fdBnoSpIB6NG",
    "outputId": "b9e55e9a-3894-4b32-f819-4a07956c416d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Downloading training data\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "#Downloading test data\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "#Class labels\n",
    "classes = ('plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "51lARMBDB6NQ",
    "outputId": "ec2960b6-af84-44fe-a896-12ebb6128815"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Anshu Garg/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now using the AlexNet\n",
    "AlexNet_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "\n",
    "#Model description\n",
    "AlexNet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AxriJWtuB6Nd"
   },
   "outputs": [],
   "source": [
    "#Updating the second classifier\n",
    "AlexNet_model.classifier[4] = torch.nn.Linear(4096,1024)\n",
    "\n",
    "#Updating the third and the last classifier that is the output layer of the network. Make sure to have 10 output nodes if we are going to get 10 class labels through our model.\n",
    "AlexNet_model.classifier[6] = torch.nn.Linear(1024,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "wMJfm8RKB6Ns",
    "outputId": "0cc21eaa-f950-443a-ba56-e5286627e8fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNet_model.eval()\n",
    "AlexNet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "No8g0M5uB6N3"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#Optimizer(SGD)\n",
    "optimizer = torch.optim.SGD(AlexNet_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGkOJFVGB6OB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.200\n",
      "[1,  4000] loss: 0.873\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = AlexNet_model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training of AlexNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4kBP1fAPKMD"
   },
   "outputs": [],
   "source": [
    "torch.save(AlexNet_model.state_dict(),'./data1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RPwGtui7B6OL",
    "outputId": "b79bea08-acf5-4152-e30b-833fedfd7008"
   },
   "outputs": [],
   "source": [
    "#Testing Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = AlexNet_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rwfaJS7B6OU"
   },
   "outputs": [],
   "source": [
    "AlexNet_model.load_state_dict(torch.load('./data1'))\n",
    "# Splitting the alexnet model\n",
    "#1st model\n",
    "module_1=torch.nn.Sequential(*list(AlexNet_model.features.children())[:-3])\n",
    "module_2=torch.nn.Sequential(*list(AlexNet_model.features.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "b1fEpIKoB6Oe",
    "outputId": "a8846c01-5a14-4b8c-ce2c-5cef2bd9a82d"
   },
   "outputs": [],
   "source": [
    "module_1.to(device)\n",
    "module_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IGmXVgiB6On"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "bSwPOnOhB6Ov",
    "outputId": "110201cd-e4f1-45ab-f6d1-cddbb4b5f4d8"
   },
   "outputs": [],
   "source": [
    "print(\"train_data.data\",train_data.data.shape)\n",
    "train_data_numpy=torch.from_numpy(train_data.data)\n",
    "train_DT = train_data_numpy.permute(0, 3, 1, 2)\n",
    "print(\"train_data_numpy\",train_data_numpy.shape)\n",
    "\n",
    "train_final=train_DT.float().to(device)\n",
    "print(train_DT.shape)\n",
    "\n",
    "test_input=torch.from_numpy(test_data.data)\n",
    "test_DT = test_input.permute(0, 3, 1, 2)\n",
    "test_final=test_DT.float().to(device)\n",
    "print(\"test_DT\",test_DT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP09NtA-B6O7"
   },
   "outputs": [],
   "source": [
    "output_1=module_1(train_final)   #50000, 256, 1, 1\n",
    "output_2=module_2(train_final)   #50000, 256, 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uC-kbmVB6PD"
   },
   "outputs": [],
   "source": [
    "output_1=output_1.cpu().detach().numpy()\n",
    "output_2=output_2.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "pN8E9uSEB6PN",
    "outputId": "69693bbc-9747-47b3-f6be-e31a158051cb"
   },
   "outputs": [],
   "source": [
    "final_out_1=output_1.reshape(output_1.shape[0], output_1.shape[1]*output_1.shape[2]*output_1.shape[3])\n",
    "final_out_2=output_2.reshape(output_2.shape[0], output_2.shape[1]*output_2.shape[2]*output_2.shape[3])\n",
    "print(final_out_1.shape)\n",
    "print(final_out_2.shape)\n",
    "\n",
    "labels_array=np.array(train_data.targets)\n",
    "print(labels_array.flatten().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "-4MJdPvwxv9Y",
    "outputId": "20ed865e-fe9b-4d4e-cff2-872d304cdc59"
   },
   "outputs": [],
   "source": [
    "#train SVM 1\n",
    "svm1 = svm.LinearSVC()\n",
    "svm1.fit(final_out_1, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "k698brxpicnx",
    "outputId": "0670171c-874b-42be-b4bb-0e15d4bb4160"
   },
   "outputs": [],
   "source": [
    "#train SVM 2\n",
    "svm2 = svm.LinearSVC()\n",
    "svm2.fit(final_out_2, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gv5EtYENG9A"
   },
   "outputs": [],
   "source": [
    "#Find intermediate output of Alexnet architecture\n",
    "test_output_1=module_1(test_final)\n",
    "test_output_2=module_2(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuStfGUMRLtz"
   },
   "outputs": [],
   "source": [
    "test_output_1=test_output_1.cpu().detach().numpy()\n",
    "test_output_2=test_output_2.cpu().detach().numpy()\n",
    "\n",
    "test_final_out_1=test_output_1.reshape(test_output_1.shape[0], test_output_1.shape[1]*test_output_1.shape[2]*test_output_1.shape[3])\n",
    "test_final_out_2=test_output_2.reshape(test_output_2.shape[0], test_output_2.shape[1]*test_output_2.shape[2]*test_output_2.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbmFd_qihE09"
   },
   "outputs": [],
   "source": [
    "#predicting first SVM\n",
    "svm_test_pred = svm1.predict(test_final_out_1) \n",
    "\n",
    "#predicting second SVM\n",
    "svm_test_pred_2 = svm2.predict(test_final_out_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "vKh_pElUgpyy",
    "outputId": "ea1efbf1-2b3f-4d85-a759-473554c41bae"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "test_out = np.array(test_data.targets)\n",
    "accuracy = svm1.score(test_final_out_1, test_out)\n",
    "print(\"Accuracy of SVM1 - \", accuracy)\n",
    "print(\"Classification Report for SVM1\")\n",
    "cls_rpt = classification_report(test_out, svm_test_pred) \n",
    "print(cls_rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "LnmStayAnvNT",
    "outputId": "4a519006-6777-418b-d430-fe9f6e7f7be6"
   },
   "outputs": [],
   "source": [
    "accuracy2 = svm2.score(test_final_out_2, test_out)\n",
    "print(\"Accuracy of SVM2 - \", accuracy2)\n",
    "print(\"Classification Report for SVM2\")\n",
    "cls_rpt2 = classification_report(test_out, svm_test_pred_2) \n",
    "print(cls_rpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Explainable_Medical_Image_Classifier_based_on_Human_Diagnosis_Behaviour_PT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
